This section will outline the different areas of knowledge that a reader of this
paper will need to be familiar with in order to be able to successfully
interpret the research presented.

The reader should:
\begin{inparaenum}[(1)]
\item be familiar with various aspects of hardware performance, especially those
  associated with inter-charge mobile life expectancy.  Much of the research
  here-in has to do with how computer usage and hardware design affects this
  life expectancy and what can be done to make mobile devices last longer on a
  single charge;
\item be familiar with Cloud Services and how they are used.  The research deals
  heavily with the different demands that Cloud Services make on mobile
  computing hardware compared to traditional desktop equivalents of the same
  services;
\item be familiar with the offerings available currently in today's mobile
  computing environment.  The research will discuss various performance costs
  and benefits in relation to traditional notebooks, netbooks, and smart-phones;
  and;
\item a cursory understanding of software testing.  Some of the procedures the
  researcher will be using will center around automating the testing of various
  aspects of computer performance on various mobile platforms as well as in the
  cloud.
\end{inparaenum}

The problem that this research project is addressing is as follows: Currently,
adoption of ultra-mobile PCs has primarily been driven by price.  The author
believes that the reason wider spread adoption hasn't been seen yet is of a dual
nature:
\begin{inparaenum}[(1)]
\item Mobile platform providers are still designing their machines to primarily
  behave as a stripped down desktop.  As such, they do not optimize for use of
  Cloud Services in such a way that their device will experience longer battery
  life and better performance in that context; and
\item Consumers still believe that computers are primarily for executing tasks
  locally.  The author believes that this is no longer true, both from personal
  experience as well as from usage reports.  However, consumer perception is as
  if not more important than actual facts.
\end{inparaenum}
The problem, then, is discovering what factors would have to coincide to produce
an ideal mobile platform for the public consumer.

The questions and hypotheses being addressed are as follows:
\begin{inparaenum}[(1)]
  \item The author's main hypothesis is that mass adoption of ultra-mobile PCs
    will not be seen until hardware offerings are designed to maximize length of
    use and cloud service utilization performance.  Tightly integrated here is
    the question: What would the ideal public consumer mobile platform, designed
    to take full advantage of cloud services, look like?
  \item A corollary hypothesis is that Netbooks and Notebooks perform nearly
    indistinguishably from each other when utilizing cloud services despite the
    observable differences in performance when using local applications.
\end{inparaenum}

The procedure that the researcher wishes to pursue for this project is split
into 2 areas of investigation:
\begin{inparaenum}[(1)]
\item hampered mobile platform adoption and;
\item netbook/notebook performance comparability.
\end{inparaenum}

The author intends to investigate research that has already been done in the
area of battery life performance.  It is somewhat common knowledge that a bright
display, WiFi, and Bluetooth are the biggest killers of battery life.  The
author would like to investigate if there is verifiable truth to that claim.

The primary strategy for investigating Netbook vs. Notebook performance will be
testing performance for services offered both locally and in the cloud.  This
will attempt to verify that there is indeed little to no difference between
Netbook and Notebook performance when the cloud is what is being utilized.

\section{Instrumentation}

%What do you need to do your project.  Only a couple paragraphs.

Equipment needed to reconduct my study would be
\begin{inparaenum}[(1)]
\item A MacBook;
\item An acer ASPIRE one;
\item Several Browsers;
\item OpenOffice.org;
\item The testing Spreadsheet.\footnote{Spreadsheet published here:
  \url{j.mp/cmscu498GSs}}
\item A Google account with access to Google Docs for spreadsheet analysis.
\item A clock or stopwatch to measure performance\footnote{The researcher used
  iChrono found here: \url{http://widgets.tossen.net/}}.
\end{inparaenum}

The MacBook needs the specifications outlined in table~\ref{macbookSpecs} on
page~\pageref{macbookSpecs} with the software listed in
table~\ref{macbookSoftware} on page~\pageref{macbookSoftware} installed.

The acer ASPIRE one needs the specifications outlined in table~\ref{aspireSpecs}
on page~\pageref{aspireSpecs} and the software listed in
table~\ref{aspireSoftware} on page~\pageref{aspireSoftware} installed.

\input{table.macbookSpecs.tex}

\input{table.macbookSoftware.tex}

\input{table.aspireSpecs.tex}

\input{table.aspireSoftware.tex}

Generalization would be difficult because only Intel Core Duo and Atom
Processors are being tested.  Also, a single broadband Internet connection was
used to conduct the testing so speed differences have not been fully explored.
Different office suites offer different performance characteristics and only one
has been explored.  However, none of these considerations should overly affect
the ability to generalize.  Most of today's mobile machines use processors with
very similar performance characteristics and office suites also are becoming
indistinguishable.

It is impossible to prove the generalization of this research because there was
not enough time or resources to truly test on varied hardware and over various
connection.  That being said, there is no reason why the outcomes of the testing
would vary too widely across multiple mobile platforms.  Also, performance
testing was somewhat arbitrary as actual process sampling could not be
accomplished.  Instead, observation alone was used in conjunction with the
system monitoring applications of the respective operating systems.

\section{Procedure/Methodology}

%Expected recipe

The steps taken by the researcher to test performance are the following:

\begin{enumerate}

\item Create a source CSV file with ~3,000 random numbers between -1 and 1.

\item Create a new spreadsheet based on the CSV file.

\item Create a new column and fill with the function =An*10+1 where n is the
  current row.

\item Create a new column and fill with the function =MEDIAN(B1:Bn) where n is
  the current row.

\item Create a new column and enter 1-100 in the first hundred rows.

\item Create a new column and fill with the function =Dn/100 where n is the
  current row.

\item Create a new column and fill with the function =PERCENTILE(C1:C10004,En)
  where n is the current row.

\item Change an A column cell.

\end{enumerate}

The researcher used a Groovy script with the argument .25 to generate the random
numbers used to seed the functions of the spreadsheet.  For source
see listing~\ref{randomSourceGen.groovy} in appendix~\ref{sourceCode}.

On the MacBook in Google Chrome, creation of the spreadsheet from the source
file took an average of 6 seconds based on ten trial uploads on the MacBook in
Google Chrome. Creation of the second column took an average of 3 seconds. The
third column took significantly longer, averaging 25 seconds. Data can be found
in table~\ref{mbChromePerf} on page~\pageref{mbChromePerf}.

\input{table.mbChromePerf.tex}

The problem seemed to be filling the formula down on the entire column.  Google
Spreadsheet appears to be unable to handle large column selections without
freezing.  The researcher was unable to ascertain why this would be.  No CPU
usage of note was observed and no network traffic to speak of.  On occasion
after half an hour or so the page would refresh and the data would be there, but
more often than not it simply would never show up.

Creating the 3 columns needed to calculate percentiles was uninteresting.  Each
task averaged less than 1 second over 10 runs.

As was expected, performance was extremely comparable on the ASPIRE one when
using Chrome. See table~\ref{aspChrPerf} on page~\pageref{aspChrPerf}.

\input{table.aspChrPerf.tex}

Creating the 3 columns needed to calculate percentiles remained uninteresting.

As an aside: while no significant difference at all was observed between the
two platforms' ability to compute the calculations demanded by the spreadsheet,
significant differences were observed in the performance associated with
changing the display of the data.  It appears that Google offloads most of the
data into memory and relies on local calculations to redisplay the data in the
window.  With the weaker CPU and Memory set, the Netbook saw performance losses
due to that.

At the sampling size Google Docs could handle before becoming unusable, creating
each of the columns of the Spreadsheet was instantaneous \emph{on both
  platforms}.  This was very surprising to the researcher although in retrospect
it should not have been.  At that sample size, no local spreadsheet system has
issues.  The researcher obtained a much larger spreadsheet\footnote{A testing
  spreadsheet for use with OpenOffice.org bug 89976
  \url{http://j.mp/cmscu498OOoSs}} which allowed a much closer comparison of the
two platforms and as expected the netbook performed far worse than the notebook;
actually an \emph{order of magnitude} worse. See table~\ref{ooCp} on
page~\pageref{ooCp}.

\input{table.ooCp.tex}

\section{Delimitations}

%Suggestions for future research?

Limitations in the Google Docs platform constrained the size of the testing
spreadsheet greatly.  A different service could be used to get a more realistic
baseline for cloud versus local performance comparison.

Only two platforms, a single browser, and a single office suite were tested on,
albeit across multiple platforms.  More hardware and software configurations
could be tested to help validate the generalization of the research conclusions.

\section{Results}

In general, the researcher was amazed to find that Google Docs is virtually
unusable in it's present form for spreadsheets of any reasonabel size.  While
taking on almost no CPU usage locally at all, it still took large amounts of
time to enter formulas and calculate their values for a relatively small set
(3,000) of data points.  Compared to OpenOffice.org on either platform, this was
extremely slow.  Interestingly enough, CPU and Bandwidth did not seem to play a
factor in Google Docs performance.  The researcher's only guess is that the way
they allocate computing resources at Google isn't optimized for response time.

These results are not very arbitrary but they are purely based on observation
which means that future researchers will come up with slightly different
results.  The results are demonstrated for verification by the tables of
performance data included in this text
